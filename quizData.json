{
  "1": [
    {
      "id": "1.1",
      "text": "Почему события B₀, B₁, B₂ образуют полную группу? Какие условия необходимы?",
      "options": [
        "Попарная несовместимость и полнота (сумма вероятностей = 1)",
        "Только попарная несовместимость",
        "Только полнота (сумма = 1)",
        "Независимость событий"
      ],
      "correct": 0,
      "explanation": "События образуют полную группу, если: 1) Bᵢ ∩ Bⱼ = ∅ (несовместимы), 2) P(B₀) + P(B₁) + P(B₂) = 1 (полнота). В задаче: 0.6 + 0.3 + 0.1 = 1.0 ✓"
    },
    {
      "id": "1.2",
      "text": "Выведите формулу полной вероятности из аксиом.",
      "options": [
        "P(A) = Σ P(Bᵢ) · P(A|Bᵢ) через разбиение и аксиому аддитивности",
        "P(A) = Σ P(A|Bᵢ) без весов P(Bᵢ)",
        "P(A) = P(A|B₁) + P(A|B₂) + P(A|B₃)",
        "P(A) = max{P(A|Bᵢ)}"
      ],
      "correct": 0,
      "explanation": "Вывод: A = A ∩ Ω = A ∩ (⋃Bᵢ) = ⋃(A ∩ Bᵢ). Применяем аддитивность: P(A) = Σ P(A ∩ Bᵢ). Используем P(A ∩ Bᵢ) = P(Bᵢ) · P(A|Bᵢ)."
    },
    {
      "id": "1.3",
      "text": "Можно ли складывать условные вероятности P(A|Bᵢ) напрямую?",
      "options": [
        "Нет, они нормированы на разные подпространства",
        "Да, если их сумма ≤ 1",
        "Да, если события Bᵢ равновероятны",
        "Да, условные вероятности всегда суммируются"
      ],
      "correct": 0,
      "explanation": "P(A|Bᵢ) — доля внутри подпространства Bᵢ. Пример провала: 0.9 + 0.3 + 0.5 = 1.7 > 1. Правильно: взвешивать через P(Bᵢ)."
    },
    {
      "id": "1.4",
      "text": "Когда использовать формулу Байеса вместо полной вероятности?",
      "options": [
        "Когда нужно найти P(Bᵢ|A) — вероятность причины при известном следствии",
        "Когда нужно найти P(A) — вероятность следствия",
        "Когда события независимы",
        "Когда P(A) = 1"
      ],
      "correct": 0,
      "explanation": "Полная вероятность: P(A) — прямая задача. Байес: P(Bᵢ|A) = P(Bᵢ)·P(A|Bᵢ)/P(A) — обратная задача (от следствия к причине)."
    },
    {
      "id": "1.5",
      "text": "P(A) = 0.68. Что это означает для страховой компании?",
      "options": [
        "При 1000 контрактов ожидаем ~680 перезаключений",
        "Ровно 680 контрактов будут перезаключены",
        "Не более 680 перезаключений",
        "Минимум 680 перезаключений"
      ],
      "correct": 0,
      "explanation": "Частотная интерпретация ЗБЧ: при большом числе испытаний относительная частота стремится к вероятности. ~680 — ожидаемое значение, не гарантия."
    },
    {
      "id": "1.6",
      "text": "Как проверить правильность вычисленной вероятности P(A)?",
      "options": [
        "P(A) ∈ [0,1], Σ P(Bᵢ) = 1, граничные случаи",
        "Только проверить, что P(A) ≤ 1",
        "Только проверить граничные случаи",
        "Сравнить с P(A|B₀)"
      ],
      "correct": 0,
      "explanation": "Санитарные проверки: диапазон [0,1], полнота группы Σ P(Bᵢ) = 1, граничные случаи (все P(A|Bᵢ)=1 → P(A)=1)."
    },
    {
      "id": "1.7",
      "text": "Можно ли решить задачу через дерево событий?",
      "options": [
        "Да, дерево — визуальный эквивалент формулы полной вероятности",
        "Нет, дерево применимо только для независимых событий",
        "Да, но только для двух событий",
        "Нет, дерево дает другой результат"
      ],
      "correct": 0,
      "explanation": "Дерево визуализирует разбиение: каждая ветвь = P(Bᵢ) × P(A|Bᵢ), сумма ветвей = P(A). Результат идентичен формуле."
    },
    {
      "id": "1.8",
      "text": "В чём разница между несовместимыми и независимыми событиями?",
      "options": [
        "Несовместимые: A ∩ B = ∅. Независимые: P(A ∩ B) = P(A)·P(B)",
        "Это одно и то же",
        "Несовместимые всегда независимы",
        "Независимые всегда несовместимы"
      ],
      "correct": 0,
      "explanation": "Несовместимые не могут произойти вместе (P(A ∩ B) = 0). Независимые не влияют друг на друга. ВАЖНО: несовместимые с P>0 НЕ могут быть независимыми!"
    },
    {
      "id": "1.9",
      "text": "Справедлива ли линейность математического ожидания E[X + Y] = E[X] + E[Y] для зависимых случайных величин?",
      "options": [
        "Да, линейность работает ВСЕГДА, даже для зависимых величин",
        "Нет, только для независимых",
        "Да, но только если Cov(X,Y) = 0",
        "Да, но только если X и Y одинаково распределены"
      ],
      "correct": 0,
      "explanation": "КРИТИЧЕСКИ ВАЖНОЕ СВОЙСТВО! Линейность E[aX + bY] = aE[X] + bE[Y] работает ВСЕГДА, независимо от зависимости между X и Y. Это фундаментальное свойство используется в Задаче 2 (купоны): E[T₁ + T₂ + ... + Tₙ] = E[T₁] + E[T₂] + ... + E[Tₙ], хотя Tᵢ зависимы!"
    }
  ],
  "2": [
    {
      "id": "2.1",
      "text": "Какое распределение описывает число покупок до первого нового купона?",
      "options": [
        "Геометрическое распределение Geom(p)",
        "Биномиальное распределение",
        "Распределение Пуассона",
        "Нормальное распределение"
      ],
      "correct": 0,
      "explanation": "Геометрическое распределение моделирует число испытаний до первого успеха. P(X = k) = (1-p)^(k-1) · p, E[X] = 1/p."
    },
    {
      "id": "2.2",
      "text": "Сколько купонов нужно собрать в среднем для получения всех n различных?",
      "options": [
        "n · H(n), где H(n) = 1 + 1/2 + ... + 1/n — гармоническое число",
        "n²",
        "n · log(n)",
        "n!"
      ],
      "correct": 0,
      "explanation": "E[T] = n·H(n). Для n=5: E[T] = 5·(1 + 1/2 + 1/3 + 1/4 + 1/5) ≈ 11.42. Следует из линейности матожидания."
    },
    {
      "id": "2.3",
      "text": "Если уже собрано k купонов, какова вероятность получить новый?",
      "options": [
        "(n - k) / n",
        "k / n",
        "1 / n",
        "1 - k/n"
      ],
      "correct": 0,
      "explanation": "Осталось (n - k) ненайденных из n возможных. Вероятность нового купона = (n - k) / n. При k=0: p=1 (все новые), при k=n-1: p=1/n."
    },
    {
      "id": "2.4",
      "text": "Почему E[T] растёт быстрее, чем n?",
      "options": [
        "Последние купоны встречаются редко (эффект гармонической суммы)",
        "Потому что купоны равновероятны",
        "Из-за независимости покупок",
        "Потому что n! растёт быстро"
      ],
      "correct": 0,
      "explanation": "H(n) ~ ln(n) + γ. Последний купон требует в среднем n покупок (p=1/n). Асимптотика: E[T] ≈ n·ln(n)."
    },
    {
      "id": "2.5",
      "text": "Как проверить правильность вычисленного E[T] через симуляцию?",
      "options": [
        "Запустить 10000 симуляций, усреднить результаты, проверить близость к n·H(n)",
        "Проверить, что E[T] < n",
        "Сравнить с медианой",
        "Проверить, что E[T] = n²"
      ],
      "correct": 0,
      "explanation": "Закон больших чисел: среднее N испытаний → E[T] при N → ∞. Для n=5, H(5)≈2.28, E[T]≈11.42. Симуляция должна дать ~11.3-11.5."
    },
    {
      "id": "2.6",
      "text": "Что такое линейность математического ожидания?",
      "options": [
        "E[X + Y] = E[X] + E[Y] даже для зависимых величин",
        "E[X + Y] = E[X] + E[Y] только для независимых",
        "E[X · Y] = E[X] · E[Y]",
        "E[aX] = a·E[X] только для a > 0"
      ],
      "correct": 0,
      "explanation": "Линейность: E[Σ Xᵢ] = Σ E[Xᵢ] всегда, независимо от зависимости. В задаче: E[T] = E[T₁] + E[T₂] + ... + E[Tₙ] = Σ 1/pᵢ."
    },
    {
      "id": "2.7",
      "text": "Как изменится E[T], если n увеличится вдвое?",
      "options": [
        "Более чем вдвое из-за логарифмического роста",
        "Ровно вдвое",
        "Менее чем вдвое",
        "В четыре раза"
      ],
      "correct": 0,
      "explanation": "E[T] = n·H(n) ≈ n·ln(n). Если n → 2n: E[2n] ≈ 2n·ln(2n) = 2n·(ln2 + lnn) > 2·E[n]. Рост ускоряется."
    }
  ],
  "3": [
    {
      "id": "3.1",
      "text": "Что измеряет статистика Колмогорова-Смирнова D?",
      "options": [
        "Максимальное расстояние между эмпирической и теоретической функцией распределения",
        "Среднее квадратичное отклонение выборки",
        "Корреляцию между выборками",
        "Вероятность ошибки первого рода"
      ],
      "correct": 0,
      "explanation": "D = sup|Fₙ(x) - F(x)|, где Fₙ — эмпирическая функция распределения, F — теоретическая. Измеряет максимальное вертикальное расстояние."
    },
    {
      "id": "3.2",
      "text": "Как строится эмпирическая функция распределения Fₙ(x)?",
      "options": [
        "Fₙ(x) = (число наблюдений ≤ x) / n — ступенчатая функция",
        "Fₙ(x) = среднее значение выборки",
        "Fₙ(x) = медиана выборки",
        "Fₙ(x) = теоретическая функция распределения"
      ],
      "correct": 0,
      "explanation": "Fₙ(x) = #{Xᵢ ≤ x}/n. Ступенчатая функция: скачок 1/n в каждой точке выборки. При n → ∞ сходится к F(x) (теорема Гливенко-Кантелли)."
    },
    {
      "id": "3.3",
      "text": "Почему используется sup (супремум), а не просто максимум?",
      "options": [
        "Функции распределения непрерывны, максимум может не достигаться — нужна точная верхняя грань",
        "Супремум работает быстрее на компьютере",
        "Максимум применим только для дискретных распределений",
        "Супремум и максимум — одно и то же"
      ],
      "correct": 0,
      "explanation": "Для непрерывных F(x) расстояние может не достигать максимума в конкретной точке. sup = точная верхняя грань на всей прямой."
    },
    {
      "id": "3.4",
      "text": "Какое распределение имеет статистика D при H₀: выборка из F(x)?",
      "options": [
        "Распределение Колмогорова (не зависит от F при больших n)",
        "Нормальное распределение",
        "Хи-квадрат распределение",
        "Экспоненциальное распределение"
      ],
      "correct": 0,
      "explanation": "Распределение Колмогорова не зависит от конкретного вида F (свойство инвариантности). Это позволяет использовать табличные критические значения."
    },
    {
      "id": "3.5",
      "text": "Как провести тест Колмогорова через симуляцию?",
      "options": [
        "Сгенерировать M выборок из F, вычислить D для каждой, построить эмпирическое распределение",
        "Сгенерировать одну выборку и усреднить",
        "Использовать только теоретическую функцию распределения",
        "Проверить нормальность через Q-Q plot"
      ],
      "correct": 0,
      "explanation": "Алгоритм: 1) Генерируем M выборок (например, 10000) из F. 2) Для каждой вычисляем D. 3) Эмпирическая функция распределения этих D → распределение Колмогорова."
    },
    {
      "id": "3.6",
      "text": "Для Exp(1) и n=100, какой порядок D ожидаем?",
      "options": [
        "D ~ 0.1-0.15 (критическое значение при α=0.05: ~0.136)",
        "D ~ 0.5-0.7",
        "D всегда < 0.01",
        "D = 1"
      ],
      "correct": 0,
      "explanation": "Для n=100 критическое значение Dкрит ≈ 1.36/√n ≈ 0.136 при α=0.05. Эмпирическое D будет флуктуировать вокруг этого значения."
    },
    {
      "id": "3.7",
      "text": "Что такое p-value в контексте теста Колмогорова?",
      "options": [
        "Вероятность получить D ≥ Dнабл при H₀",
        "Вероятность H₀",
        "Вероятность ошибки второго рода",
        "Критическое значение статистики"
      ],
      "correct": 0,
      "explanation": "p-value = P(D ≥ Dнабл | H₀). Если p-value < α (например, 0.05), отвергаем H₀. Малое p-value означает, что наблюдаемое отклонение маловероятно при H₀."
    },
    {
      "id": "3.8",
      "text": "Как проверить правильность симуляции через график?",
      "options": [
        "Наложить эмпирическую функцию распределения статистики D на теоретическое распределение Колмогорова",
        "Построить гистограмму выборки",
        "Проверить среднее значение",
        "Сравнить с нормальным распределением"
      ],
      "correct": 0,
      "explanation": "График: ось X — значения D, ось Y — функция распределения. Эмпирическая (из симуляции) должна быть близка к теоретической (Колмогорова). Визуальная проверка сходимости."
    },
    {
      "id": "3.9",
      "text": "Почему критерий Колмогорова лучше критерия χ² Пирсона?",
      "options": [
        "Не требует группировки данных, работает с непрерывными распределениями",
        "Всегда мощнее критерия χ² Пирсона",
        "Работает быстрее",
        "Даёт точное p-value без симуляции"
      ],
      "correct": 0,
      "explanation": "χ² требует разбиения на интервалы (потеря информации). Колмогоров использует все точки выборки. Преимущество для непрерывных распределений."
    },
    {
      "id": "3.10",
      "text": "При проверке распределения статистики Колмогорова Dₙ для n=500, что необходимо сделать ОБЯЗАТЕЛЬНО перед сравнением с теоретическим распределением K(z)?",
      "options": [
        "Умножить Dₙ на √n (масштабировать)",
        "Разделить Dₙ на n",
        "Ничего, сравнить напрямую",
        "Взять логарифм Dₙ"
      ],
      "correct": 0,
      "explanation": "КРИТИЧЕСКИ ВАЖНО! Без масштабирования на √n статистика Dₙ → 0 при n → ∞, графики не совпадут (Dₙ ≈ 0.04, а K(z) имеет максимум ≈ 0.8). Теорема Колмогорова: √n·Dₙ → K(z) при n → ∞. Это САМАЯ ЧАСТАЯ ошибка в Задаче 3! В эталонах: plt.plot(z_grid, ks_dist.cdf(np.sqrt(n)*D_values))."
    }
  ],
  "4": [
    {
      "id": "4.1",
      "text": "Что такое VaR (Value at Risk)?",
      "options": [
        "Квантиль распределения убытков — пороговое значение, которое не будет превышено с заданной вероятностью",
        "Среднее значение убытков",
        "Стандартное отклонение доходности",
        "Вероятность дефолта"
      ],
      "correct": 0,
      "explanation": "VaRₐ = -qₐ(R) — α-квантиль распределения потерь. Для α=0.05: в 95% случаев убыток не превысит VaR. ВАЖНО: VaR — это КВАНТИЛЬ, а НЕ математическое ожидание! В эталонах: var_5_5d = np.quantile(returns, 0.05)."
    },
    {
      "id": "4.2",
      "text": "Что такое 5-дневный VaR с уровнем доверия 95%?",
      "options": [
        "Максимальный убыток за 5 дней, который не будет превышен в 95% случаев",
        "Средний убыток за 5 дней",
        "Убыток, который случится ровно через 5 дней",
        "5% вероятность убытка"
      ],
      "correct": 0,
      "explanation": "5-дневный VaR учитывает кумулятивную доходность за 5 дней. Если однодневная волатильность σ, то 5-дневная ≈ σ√5 (при iid допущении)."
    },
    {
      "id": "4.3",
      "text": "Что проверяет тест Купица (Kupiec POF test)?",
      "options": [
        "Соответствует ли частота нарушений VaR ожидаемому уровню α",
        "Независимость нарушений VaR",
        "Нормальность распределения доходностей",
        "Стационарность временного ряда"
      ],
      "correct": 0,
      "explanation": "Kupiec POF (Proportion of Failures) тестирует H₀: p = α, где p — истинная доля нарушений. Статистика: LR = -2ln[L(p̂)/L(α)] ~ χ²(1)."
    },
    {
      "id": "4.4",
      "text": "Для VaR 95% на 250 торговых днях сколько нарушений ожидается?",
      "options": [
        "12-13 нарушений (250 × 0.05 = 12.5)",
        "5 нарушений",
        "50 нарушений",
        "0 нарушений"
      ],
      "correct": 0,
      "explanation": "При α = 0.05 и N = 250 ожидаемое число нарушений = N × α = 250 × 0.05 = 12.5. Наблюдаемое X ~ Binomial(N, α)."
    },
    {
      "id": "4.5",
      "text": "Базельские зоны (Basel III) определены для каких параметров?",
      "options": [
        "99% VaR (α=0.01), N=250 торговых дней",
        "95% VaR (α=0.05), N=250 дней",
        "95% VaR (α=0.05), N=50 дней",
        "Не зависят от параметров"
      ],
      "correct": 0,
      "explanation": "Базельские зоны (Basel Committee III) для 99% VaR за 250 дней: Зелёная 0-4, Жёлтая 5-9, Красная ≥10 нарушений. ВАЖНО: Стандарт Basel определён для α=0.01 (99% доверительный интервал), а НЕ для α=0.05! Для α=0.05 зоны нужно пересчитывать через биномиальное распределение."
    },
    {
      "id": "4.6",
      "text": "Что проверяет тест Кристофферсена (Christoffersen test)?",
      "options": [
        "Независимость нарушений VaR (нет кластеризации)",
        "Частоту нарушений VaR",
        "Нормальность остатков",
        "Гетероскедастичность"
      ],
      "correct": 0,
      "explanation": "Тест независимости: проверяет, что нарушения не кластеризуются (нет автокорреляции). Статистика: LRind = -2ln[L(марковская модель)/L(независимая)] ~ χ²(1)."
    },
    {
      "id": "4.7",
      "text": "Что такое 'нарушение VaR' (exception)?",
      "options": [
        "Событие, когда фактический убыток превышает VaR",
        "Событие, когда VaR = 0",
        "Положительная доходность",
        "Волатильность выше среднего"
      ],
      "correct": 0,
      "explanation": "Нарушение: Loss > VaR или доходность < -VaR (в зависимости от знаковой конвенции). Индикатор: Iₜ = 1, если нарушение, 0 иначе."
    },
    {
      "id": "4.8",
      "text": "Как вычислить 5-дневный VaR из однодневного при iid допущении?",
      "options": [
        "VaR₅ = VaR₁ × √5",
        "VaR₅ = VaR₁ × 5",
        "VaR₅ = VaR₁ / √5",
        "VaR₅ = VaR₁²"
      ],
      "correct": 0,
      "explanation": "Для iid доходностей волатильность масштабируется как √T. VaRₜ = zₐ × σ × √T. Для 5 дней: VaR₅ = VaR₁ × √5."
    },
    {
      "id": "4.9",
      "text": "Почему используется исторический метод для VaR?",
      "options": [
        "Не требует предположений о распределении (non-parametric)",
        "Всегда точнее параметрических методов",
        "Работает быстрее Monte Carlo",
        "Учитывает будущие события"
      ],
      "correct": 0,
      "explanation": "Исторический VaR = эмпирический α-квантиль выборки. Не требует нормальности. Недостаток: зависит от истории (не учитывает структурные изменения)."
    },
    {
      "id": "4.10",
      "text": "Что означает p-value теста Купица = 0.03 при α = 0.05?",
      "options": [
        "Отвергаем H₀: модель VaR неадекватна (слишком много или мало нарушений)",
        "Принимаем H₀: модель адекватна",
        "Нужно увеличить выборку",
        "VaR слишком консервативен"
      ],
      "correct": 0,
      "explanation": "p-value < 0.05 → отвергаем H₀. Означает, что наблюдаемая частота нарушений статистически отличается от ожидаемой α."
    },
    {
      "id": "4.11",
      "text": "В чём разница между VaR и ES (Expected Shortfall)?",
      "options": [
        "VaR — квантиль, ES — среднее за хвостом (условное матожидание)",
        "VaR и ES — одно и то же",
        "ES всегда меньше VaR",
        "VaR учитывает экстремальные события, ES — нет"
      ],
      "correct": 0,
      "explanation": "VaR = квантиль. ES (CVaR) = E[Loss | Loss > VaR]. ES всегда ≥ VaR и учитывает величину хвостовых событий. ES — когерентная мера риска."
    },
    {
      "id": "4.12",
      "text": "Почему НЕЛЬЗЯ использовать скользящие окна [0:5], [1:6], [2:7]... для backtesting 5-дневного VaR?",
      "options": [
        "Окна перекрываются → наблюдения зависимы → тест Купика неприменим",
        "Слишком много вычислений",
        "Python не поддерживает такие срезы",
        "VaR считается только для полных недель"
      ],
      "correct": 0,
      "explanation": "Тест Купица предполагает НЕЗАВИСИМЫЕ испытания Бернулли (биномиальное распределение). Скользящие окна дают 4 общих дня из 5 → сильная зависимость → занижены стандартные ошибки → неверные p-value и искажённые выводы. ПРАВИЛЬНО: неперекрывающиеся блоки [0:5], [5:10], [10:15]... Это критическая ошибка!"
    },
    {
      "id": "4.13",
      "text": "Какой уровень значимости (α) используется в стандарте Basel III для VaR?",
      "options": [
        "α = 0.01 (99% доверительный интервал)",
        "α = 0.05 (95% доверительный интервал)",
        "α = 0.10 (90% доверительный интервал)",
        "α зависит от типа актива"
      ],
      "correct": 0,
      "explanation": "Basel Committee on Banking Supervision требует 99% VaR (α=0.01) на горизонте 10 дней (или эквивалент). При использовании α=0.05 (95% VaR) базельские зоны (0-4, 5-9, ≥10) НЕПРИМЕНИМЫ и должны быть пересчитаны! Это частая ошибка при интерпретации результатов backtesting."
    }
  ],
  "5": [
    {
      "id": "5.1",
      "text": "Что оценивает коэффициент β₁ в модели Y = β₀ + β₁X + ε?",
      "options": [
        "Изменение Y при увеличении X на 1 единицу (предельный эффект)",
        "Среднее значение Y",
        "Корреляцию между X и Y",
        "Дисперсию Y"
      ],
      "correct": 0,
      "explanation": "β₁ — наклон регрессии. Интерпретация: при увеличении X на 1 единицу Y изменяется на β₁ (при прочих равных). β₀ — свободный член (intercept)."
    },
    {
      "id": "5.2",
      "text": "Что такое R² (коэффициент детерминации)?",
      "options": [
        "Доля объясненной дисперсии: R² = 1 - RSS/TSS",
        "Корреляция между X и Y",
        "Стандартная ошибка регрессии",
        "p-value регрессии"
      ],
      "correct": 0,
      "explanation": "R² ∈ [0,1] показывает, какая доля вариации Y объясняется моделью. R² = SSR/TSS = 1 - RSS/TSS, где TSS — полная вариация, RSS — остаточная."
    },
    {
      "id": "5.3",
      "text": "Как интерпретировать R² = 0.75?",
      "options": [
        "Модель объясняет 75% вариации Y, 25% — случайные факторы",
        "Модель правильная на 75%",
        "75% наблюдений точны",
        "Корреляция = 0.75"
      ],
      "correct": 0,
      "explanation": "R² = 0.75 означает: 75% разброса Y объясняется регрессией на X. Оставшиеся 25% — влияние других факторов и шум."
    },
    {
      "id": "5.4",
      "text": "Что проверяет t-тест для коэффициента β₁?",
      "options": [
        "H₀: β₁ = 0 (X не влияет на Y)",
        "H₀: β₁ = 1",
        "H₀: R² = 0",
        "H₀: остатки нормальны"
      ],
      "correct": 0,
      "explanation": "t-статистика: t = β̂₁ / SE(β̂₁) ~ t(n-2) при H₀. Если p-value < 0.05, отвергаем H₀ → X статистически значим."
    },
    {
      "id": "5.5",
      "text": "Что такое остатки (residuals) в регрессии?",
      "options": [
        "εᵢ = Yᵢ - Ŷᵢ — разница между наблюдением и предсказанием",
        "Ŷᵢ — предсказанные значения",
        "β̂₁ — оценка коэффициента",
        "R² модели"
      ],
      "correct": 0,
      "explanation": "Остатки εᵢ = Yᵢ - (β̂₀ + β̂₁Xᵢ). Должны удовлетворять: E[ε]=0, Var(ε)=σ² (гомоскедастичность), независимость, нормальность (для тестов)."
    },
    {
      "id": "5.6",
      "text": "Как проверить гомоскедастичность (равенство дисперсий остатков)?",
      "options": [
        "График остатков vs Ŷ или тест Бройша-Пагана",
        "Проверить R²",
        "Построить гистограмму Y",
        "Вычислить среднее остатков"
      ],
      "correct": 0,
      "explanation": "График εᵢ vs Ŷᵢ: если расширяющийся конус (fanning) — гетероскедастичность. Формальные тесты: Breusch-Pagan, White. При нарушении — использовать робастные SE."
    },
    {
      "id": "5.7",
      "text": "Что показывает p-value = 0.002 для β₁?",
      "options": [
        "Коэффициент статистически значим на любом разумном уровне (α = 0.05, 0.01)",
        "β₁ = 0.002",
        "Модель объясняет 0.2% дисперсии",
        "Нужно больше данных"
      ],
      "correct": 0,
      "explanation": "p-value = 0.002 < 0.05 → отвергаем H₀: β₁ = 0. Сильное доказательство влияния X на Y. Малое p-value = маловероятно наблюдать такой β̂₁ при β₁ = 0."
    },
    {
      "id": "5.8",
      "text": "Как использовать модель для прогноза?",
      "options": [
        "Подставить X_new в Ŷ = β̂₀ + β̂₁X_new, учесть доверительный интервал",
        "Взять среднее Y",
        "Экстраполировать за пределы выборки без ограничений",
        "Использовать только R²"
      ],
      "correct": 0,
      "explanation": "Точечный прогноз: Ŷ_new = β̂₀ + β̂₁X_new. Доверительный интервал учитывает SE(Ŷ_new). ВАЖНО: не экстраполировать далеко за пределы данных!"
    },
    {
      "id": "5.9",
      "text": "Почему R² не падает при добавлении переменных?",
      "options": [
        "R² всегда растёт (или не меняется) с добавлением регрессоров",
        "R² может падать при добавлении переменных",
        "R² не зависит от числа переменных",
        "R² падает, если переменные коррелированы"
      ],
      "correct": 0,
      "explanation": "R² = 1 - RSS/TSS. RSS не увеличивается при добавлении переменных (МНК минимизирует). Для сравнения моделей используется adjusted R² = 1 - (1-R²)·(n-1)/(n-k-1)."
    },
    {
      "id": "5.10",
      "text": "Что такое мультиколлинеарность?",
      "options": [
        "Высокая корреляция между регрессорами, увеличивает SE(β̂)",
        "Высокая корреляция между Y и X",
        "Нормальность остатков",
        "Гетероскедастичность"
      ],
      "correct": 0,
      "explanation": "Мультиколлинеарность: X₁ и X₂ сильно коррелированы. Следствия: большие SE, неустойчивые оценки, p-values неинформативны. Решения: удалить переменную, PCA, Ridge."
    },
    {
      "id": "5.11",
      "text": "Для регрессии Y = β₀ + β₁X, какая формула для коэффициента наклона β₁?",
      "options": [
        "β₁ = ρ · (σ_Y / σ_X)",
        "β₁ = ρ",
        "β₁ = Cov(X,Y)",
        "β₁ = σ_Y / σ_X"
      ],
      "correct": 0,
      "explanation": "β₁ = ρ·(σ_Y/σ_X) = Cov(X,Y)/Var(X). Корреляция ρ БЕЗРАЗМЕРНА, но β₁ имеет размерность [Y]/[X]. Без множителя σ_Y/σ_X ответ будет НЕВЕРНЫМ (частая ошибка в ручных расчётах)! При σ_Y = σ_X: β₁ = ρ. При σ_Y ≠ σ_X: β₁ ≠ ρ."
    }
  ]
}
